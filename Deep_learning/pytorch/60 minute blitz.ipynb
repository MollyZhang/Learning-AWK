{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -8.5899e+09,  0.0000e+00],\n",
      "        [-8.5899e+09,  4.2981e+21,  6.3828e+28],\n",
      "        [ 3.8016e-39,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.5899e+09,  0.0000e+00, -8.5899e+09]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(4,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5051, 0.5517, 0.9906],\n",
      "        [0.6874, 0.3775, 0.8861],\n",
      "        [0.8743, 0.5547, 0.4622],\n",
      "        [0.4603, 0.0146, 0.4563]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,3)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7126, 0.6919, 1.8503],\n",
      "        [1.2580, 0.8235, 1.5663],\n",
      "        [1.8027, 1.1550, 0.9255],\n",
      "        [1.0745, 0.3226, 1.3383]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(4,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7126, 0.6919, 1.8503],\n",
      "        [1.2580, 0.8235, 1.5663],\n",
      "        [1.8027, 1.1550, 0.9255],\n",
      "        [1.0745, 0.3226, 1.3383]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7126, 0.6919, 1.8503],\n",
       "        [1.2580, 0.8235, 1.5663],\n",
       "        [1.8027, 1.1550, 0.9255],\n",
       "        [1.0745, 0.3226, 1.3383]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7126, 0.6919, 1.8503],\n",
       "        [1.2580, 0.8235, 1.5663],\n",
       "        [1.8027, 1.1550, 0.9255],\n",
       "        [1.0745, 0.3226, 1.3383]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5051, 0.5517, 0.9906],\n",
       "        [0.6874, 0.3775, 0.8861],\n",
       "        [0.8743, 0.5547, 0.4622],\n",
       "        [0.4603, 0.0146, 0.4563]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9906, 0.8861, 0.4622, 0.4563])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5051],\n",
       "        [0.5517],\n",
       "        [0.9906],\n",
       "        [0.6874],\n",
       "        [0.3775],\n",
       "        [0.8861],\n",
       "        [0.8743],\n",
       "        [0.5547],\n",
       "        [0.4622],\n",
       "        [0.4603],\n",
       "        [0.0146],\n",
       "        [0.4563]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.ones(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.486343383789062e-05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"yo\")\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward>)\n",
      "tensor(27., grad_fn=<MeanBackward1>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2, requires_grad=True)\n",
    "y = x+2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(out)\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n",
    "print(out.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward>)\n",
      "tensor(27., grad_fn=<MeanBackward1>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(out)\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n",
    "print(out.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(torch.from_numpy(np.array([1.,2.,3.])), requires_grad=True)\n",
    "y = (3*x**2 + 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 102.4000, 1024.0000,    0.1024])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -809.8691,   648.2529, -1037.9739], grad_fn=<MulBackward>)\n",
      "tensor([-1.5818,  1.2661, -2.0273], requires_grad=True)\n",
      "tensor([ 51.2000, 512.0000,   0.0512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x*2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y*2\n",
    "print(y)\n",
    "\n",
    "gradients = torch.tensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d (6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120)\n",
      "  (fc2): Linear(in_features=120, out_features=84)\n",
      "  (fc3): Linear(in_features=84, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0918 -0.0065  0.0752 -0.0858  0.0375 -0.0520 -0.1249  0.0313 -0.1174 -0.0487\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1,1,32,32))\n",
    "output = net(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "output.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = Variable(torch.arange(1,11))\n",
    "target = target.view(1,-1)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 39.0085\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7f7d1a547a90>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddmmBackward object at 0x7f7d1a547be0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn.next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ExpandBackward object at 0x7f7d1a53f240>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n",
      "conv1.bias.grad after backward\n",
      "Variable containing:\n",
      " 0.0606\n",
      " 0.0368\n",
      " 0.0003\n",
      "-0.0068\n",
      "-0.0057\n",
      "-0.1064\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1,1,32,32))\n",
    "output = net(input)\n",
    "target = Variable(torch.arange(1,11))\n",
    "target = target.view(1,-1)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "\n",
    "net.zero_grad()\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), \n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5,0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "    download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "     shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "    download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, \n",
    "    shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " frog  bird horse   car\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d575ce5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img/2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(' '.join('%5s' %classes[labels[i]] for i in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.176\n",
      "[1,  4000] loss: 1.857\n",
      "[1,  6000] loss: 1.657\n",
      "[1,  8000] loss: 1.567\n",
      "[1, 10000] loss: 1.500\n",
      "[1, 12000] loss: 1.436\n",
      "[2,  2000] loss: 1.382\n",
      "[2,  4000] loss: 1.347\n",
      "[2,  6000] loss: 1.320\n",
      "[2,  8000] loss: 1.286\n",
      "[2, 10000] loss: 1.276\n",
      "[2, 12000] loss: 1.249\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = net(Variable(images.cuda()))\n",
    "\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted==labels.cuda()).sum()\n",
    "    \n",
    "print(\"Test Accuracy on 10000 test images:\", 100*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"  In Model: input size\", input.size(), \"output size\", output.size())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=5\n",
    "output_size=2\n",
    "batch_size=30\n",
    "data_size=100\n",
    "   \n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size),\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "model = Model(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's use 2 GPUs\n",
      "  In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2bf5602c33f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrand_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     print(\"Outside: input size\", input_var.size(), \n\u001b[1;32m      9\u001b[0m           \"output_size\", output.size())\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() >1:\n",
    "    print(\"let's use\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "\n",
    "for data in rand_loader:\n",
    "    input_var = Variable(data.cuda())\n",
    "    output = model(input_var)\n",
    "    print(\"Outside: input size\", input_var.size(), \n",
    "          \"output_size\", output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
