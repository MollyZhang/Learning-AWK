{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following this tutorial\n",
    "https://www.tensorflow.org/get_started/get_started#the_computational_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 4.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run([node1, node2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_2:0\", shape=(), dtype=float32)\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = node1 + node2\n",
    "print(node3)\n",
    "print(sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_6:0\", dtype=float32)\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = a + b\n",
    "print(c)\n",
    "print(sess.run(c, feed_dict={a:1, b:3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30000001]\n",
      "[-0.30000001]\n",
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(W))\n",
    "print(sess.run(b))\n",
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign value to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1])\n",
    "fixb = tf.assign(b, [1])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, loss: 4.039775371551514\n",
      "iteration: 20, loss: 0.5884453654289246\n",
      "iteration: 40, loss: 0.22313465178012848\n",
      "iteration: 60, loss: 0.08461123704910278\n",
      "iteration: 80, loss: 0.03208404406905174\n",
      "iteration: 100, loss: 0.012166056782007217\n",
      "iteration: 120, loss: 0.0046132756397128105\n",
      "iteration: 140, loss: 0.0017493258928880095\n",
      "iteration: 160, loss: 0.0006633322918787599\n",
      "iteration: 180, loss: 0.00025153032038360834\n",
      "iteration: 200, loss: 9.537827281747013e-05\n",
      "iteration: 220, loss: 3.616779940784909e-05\n",
      "iteration: 240, loss: 1.3715072782360949e-05\n",
      "iteration: 260, loss: 5.2005434554303065e-06\n",
      "iteration: 280, loss: 1.9718784187716665e-06\n",
      "iteration: 300, loss: 7.476127734662441e-07\n",
      "iteration: 320, loss: 2.8343669100650004e-07\n",
      "iteration: 340, loss: 1.0746391865268379e-07\n",
      "iteration: 360, loss: 4.076203197200812e-08\n",
      "iteration: 380, loss: 1.542969130241545e-08\n",
      "iteration: 400, loss: 5.851120477018412e-09\n",
      "iteration: 420, loss: 2.214804339928378e-09\n",
      "iteration: 440, loss: 8.377583071705885e-10\n",
      "iteration: 460, loss: 3.1799629596207524e-10\n",
      "iteration: 480, loss: 1.2015632933071174e-10\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.02)\n",
    "train = optimizer.minimize(loss)\n",
    "sess.run(init)\n",
    "for i in range(500):\n",
    "    sess.run(train, feed_dict={x: [1, 2, 3, 4], y: [0, -1, -2, -3]})   \n",
    "    if i % 20 == 0:\n",
    "        sse = sess.run(loss, feed_dict={x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "        print(\"iteration: {0}, loss: {1}\".format(i, sse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tf.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp40alwu13\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp40alwu13', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6d44112e8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp40alwu13/model.ckpt.\n",
      "INFO:tensorflow:loss = 23.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 618.749\n",
      "INFO:tensorflow:loss = 0.123438, step = 101 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.461\n",
      "INFO:tensorflow:loss = 0.0810343, step = 201 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.795\n",
      "INFO:tensorflow:loss = 0.0223364, step = 301 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.343\n",
      "INFO:tensorflow:loss = 0.00709455, step = 401 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.75\n",
      "INFO:tensorflow:loss = 0.002536, step = 501 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.96\n",
      "INFO:tensorflow:loss = 0.000399185, step = 601 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 747.873\n",
      "INFO:tensorflow:loss = 0.000134419, step = 701 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.333\n",
      "INFO:tensorflow:loss = 9.81357e-06, step = 801 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.193\n",
      "INFO:tensorflow:loss = 9.7648e-06, step = 901 (0.133 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp40alwu13/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.21142e-06.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-30-23:07:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp40alwu13/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-30-23:07:13\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 3.96531e-07, global_step = 1000, loss = 1.58613e-06\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-30-23:07:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp40alwu13/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-30-23:07:14\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00258637, global_step = 1000, loss = 0.0103455\n",
      "train metrics: {'average_loss': 3.9653128e-07, 'loss': 1.5861251e-06, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025863659, 'loss': 0.010345464, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmplmm8dg_y\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmplmm8dg_y', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6df226978>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmplmm8dg_y/model.ckpt.\n",
      "INFO:tensorflow:loss = 114.541993787, step = 1\n",
      "INFO:tensorflow:global_step/sec: 670.457\n",
      "INFO:tensorflow:loss = 0.00362417958034, step = 101 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 964.361\n",
      "INFO:tensorflow:loss = 0.000351173278993, step = 201 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 908.495\n",
      "INFO:tensorflow:loss = 2.51156516983e-05, step = 301 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 923.042\n",
      "INFO:tensorflow:loss = 1.45438947647e-06, step = 401 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.667\n",
      "INFO:tensorflow:loss = 2.67114526788e-07, step = 501 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.177\n",
      "INFO:tensorflow:loss = 1.32086239523e-08, step = 601 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.532\n",
      "INFO:tensorflow:loss = 9.24729016251e-10, step = 701 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1016.94\n",
      "INFO:tensorflow:loss = 4.74439403532e-11, step = 801 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 963.692\n",
      "INFO:tensorflow:loss = 1.5721778037e-11, step = 901 (0.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmplmm8dg_y/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.67378231262e-12.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-30-23:11:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplmm8dg_y/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-30-23:11:28\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.40755e-12\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-30-23:11:28\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplmm8dg_y/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-30-23:11:28\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101003\n",
      "train metrics: {'loss': 1.4075494e-12, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100341, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W*features['x'] + b\n",
    "\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add and tf.add, softmax, cross_entropy and softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.40000001,  0.2       ,  0.1       ], dtype=float32), array([ 4.,  2.,  7.], dtype=float32)]\n",
      "2.23849\n",
      "2.82643\n"
     ]
    }
   ],
   "source": [
    "y1 = tf.Variable(np.array([0.4, 0.2, 0.1]).astype(\"float32\"))\n",
    "y2 = tf.Variable(np.array([4, 2, 7]).astype(\"float32\"))\n",
    "y3 = tf.Variable(np.array([0.1, 0.2, 4]).astype(\"float32\"))\n",
    "xent = 0\n",
    "xent += tf.nn.softmax_cross_entropy_with_logits(labels=y1,logits=y2)\n",
    "# xent += tf.nn.softmax_cross_entropy_with_logits(labels=y2,logits=y3)\n",
    "# xent += tf.nn.softmax_cross_entropy_with_logits(labels=y1,logits=y3)\n",
    "\n",
    "softmax1 = tf.nn.softmax(y1)\n",
    "softmax2 = tf.nn.softmax(y2)\n",
    "\n",
    "xent1 = tf.reduce_mean(-tf.reduce_sum(softmax1 * tf.log(softmax2)))\n",
    "\n",
    "summ = y1 + y2\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([y1, y2]))\n",
    "    print(sess.run(xent))\n",
    "    print(sess.run(xent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,0,1,1]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
