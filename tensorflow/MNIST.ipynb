{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC MNIST ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# each image has 28x28=784 pixels, None means unrestricted number of images\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# 10 means 10 different out put classes\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=0, train accuracy=0.5299999713897705, test acurracy=0.3165999948978424\n",
      "Iteration=100, train accuracy=0.9399999976158142, test acurracy=0.8974000215530396\n",
      "Iteration=200, train accuracy=0.8999999761581421, test acurracy=0.9036999940872192\n",
      "Iteration=300, train accuracy=0.9399999976158142, test acurracy=0.9097999930381775\n",
      "Iteration=400, train accuracy=0.9300000071525574, test acurracy=0.9128000140190125\n",
      "Iteration=500, train accuracy=0.9399999976158142, test acurracy=0.9136000275611877\n",
      "Iteration=600, train accuracy=0.9399999976158142, test acurracy=0.9156000018119812\n",
      "Iteration=700, train accuracy=0.9700000286102295, test acurracy=0.916100025177002\n",
      "Iteration=800, train accuracy=0.9300000071525574, test acurracy=0.9193999767303467\n",
      "Iteration=900, train accuracy=0.949999988079071, test acurracy=0.9165999889373779\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if i % 100 == 0:\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        print(\"Iteration={0}, train accuracy={1}, test acurracy={2}\".format(\n",
    "            i, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9151\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first convolution layer\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second convolution layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully connected layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout at fully connected layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final layer for output\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss and accuracy\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.019999999552965164\n",
      "test accuracy 0.0818\n",
      "step 500, training accuracy 0.9200000166893005\n",
      "test accuracy 0.9449\n",
      "step 1000, training accuracy 0.9399999976158142\n",
      "test accuracy 0.9617\n",
      "step 1500, training accuracy 0.9800000190734863\n",
      "test accuracy 0.9702\n",
      "step 2000, training accuracy 0.9599999785423279\n",
      "test accuracy 0.9723\n",
      "step 2500, training accuracy 1.0\n",
      "test accuracy 0.9791\n",
      "step 3000, training accuracy 0.9800000190734863\n",
      "test accuracy 0.98\n",
      "step 3500, training accuracy 0.9800000190734863\n",
      "test accuracy 0.9828\n",
      "step 4000, training accuracy 1.0\n",
      "test accuracy 0.9833\n",
      "step 4500, training accuracy 0.9800000190734863\n",
      "test accuracy 0.9849\n",
      "step 5000, training accuracy 1.0\n",
      "test accuracy 0.9843\n",
      "step 5500, training accuracy 1.0\n",
      "test accuracy 0.9849\n",
      "step 6000, training accuracy 1.0\n",
      "test accuracy 0.9874\n",
      "step 6500, training accuracy 0.9800000190734863\n",
      "test accuracy 0.9884\n",
      "step 7000, training accuracy 1.0\n",
      "test accuracy 0.9895\n",
      "step 7500, training accuracy 1.0\n",
      "test accuracy 0.989\n",
      "step 8000, training accuracy 0.9800000190734863\n",
      "test accuracy 0.9881\n",
      "step 8500, training accuracy 1.0\n",
      "test accuracy 0.9902\n",
      "step 9000, training accuracy 0.9800000190734863\n",
      "test accuracy 0.9901\n",
      "step 9500, training accuracy 1.0\n",
      "test accuracy 0.9908\n",
      "step 10000, training accuracy 1.0\n",
      "test accuracy 0.9915\n",
      "step 10500, training accuracy 1.0\n",
      "test accuracy 0.9913\n",
      "step 11000, training accuracy 1.0\n",
      "test accuracy 0.9911\n",
      "step 11500, training accuracy 1.0\n",
      "test accuracy 0.9916\n",
      "step 12000, training accuracy 1.0\n",
      "test accuracy 0.9911\n",
      "step 12500, training accuracy 1.0\n",
      "test accuracy 0.9918\n",
      "step 13000, training accuracy 1.0\n",
      "test accuracy 0.9919\n",
      "step 13500, training accuracy 1.0\n",
      "test accuracy 0.9912\n",
      "step 14000, training accuracy 1.0\n",
      "test accuracy 0.9914\n",
      "step 14500, training accuracy 1.0\n",
      "test accuracy 0.9909\n",
      "step 15000, training accuracy 1.0\n",
      "test accuracy 0.991\n",
      "step 15500, training accuracy 1.0\n",
      "test accuracy 0.9927\n",
      "step 16000, training accuracy 1.0\n",
      "test accuracy 0.9921\n",
      "step 16500, training accuracy 0.9800000190734863\n",
      "test accuracy 0.9925\n",
      "step 17000, training accuracy 1.0\n",
      "test accuracy 0.9913\n",
      "step 17500, training accuracy 1.0\n",
      "test accuracy 0.9923\n",
      "step 18000, training accuracy 1.0\n",
      "test accuracy 0.9915\n",
      "step 18500, training accuracy 1.0\n",
      "test accuracy 0.9927\n",
      "step 19000, training accuracy 1.0\n",
      "test accuracy 0.9919\n",
      "step 19500, training accuracy 1.0\n",
      "test accuracy 0.9921\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 500 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step {0}, training accuracy {1}'.format(i, train_accuracy))\n",
    "            print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "                x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
