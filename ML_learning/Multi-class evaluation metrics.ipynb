{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement weighted and unweighted F1, precision, recall for multi-class classification\n",
    "2. Answer this question: could the weighted f1 score be outside the range of weighted precision and weighted recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=3, \n",
    "                           weights=[0.5, 0.25, 0.01],\n",
    "                           n_samples=10000, n_features=10, \n",
    "                           n_clusters_per_class=2, \n",
    "                    n_informative=10, n_redundant=0, n_repeated=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5778\n",
       "1    3292\n",
       "2     930\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.0001)\n",
    "lr.fit(X, y)\n",
    "y_pred = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def float_equal(n1, n2):\n",
    "    return abs(n1-n2)<1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.7676\n"
     ]
    }
   ],
   "source": [
    "accu_molly = sum((y == y_pred).astype(int))/len(y)\n",
    "accu = accuracy_score(y_true=y, y_pred=y_pred)\n",
    "print(float_equal(accu_molly,accu))\n",
    "print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_class_weighting(y_true, y_pred, func):\n",
    "    scores = []\n",
    "    counts = []\n",
    "    for each_label in set(y_true):\n",
    "        y_true_ovr = (y_true==each_label).astype(int)\n",
    "        y_pred_ovr = (y_pred==each_label).astype(int)\n",
    "        counts.append(sum(y_true_ovr))\n",
    "        scores.append(func(y_pred_ovr, y_true_ovr))\n",
    "    print(scores)\n",
    "    print(counts)\n",
    "    weighted_score = sum(np.array(scores) * np.array(counts)/sum(counts))\n",
    "    r_weighted_score = sum(np.array(scores) * (1/np.array(counts))/sum(1/np.array(counts)))\n",
    "    return weighted_score, r_weighted_score\n",
    "        \n",
    "def precision(y_pred, y):\n",
    "    positives = np.where(y_pred==1)[0]\n",
    "    return sum(y[positives])/len(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7930388637427813, 0.7401356350184957, 0.5558739255014327]\n",
      "[5778, 3292, 930]\n",
      "True\n",
      "0.7535667815903011\n",
      "0.6183817599535814\n"
     ]
    }
   ],
   "source": [
    "precision_molly, precision_molly_ = multi_class_weighting(y, y_pred, precision)\n",
    "precision_sklearn = precision_score(y_true=y, y_pred=y_pred, average=\"weighted\")\n",
    "print(float_equal(precision_molly,precision_sklearn))\n",
    "print(precision_sklearn)\n",
    "print(precision_molly_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(y_pred, y):\n",
    "    positives = np.where(y==1)[0]\n",
    "    return sum(y_pred[positives])/len(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8793700242298373, 0.7293438639125152, 0.2086021505376344]\n",
      "[5778, 3292, 930]\n",
      "True\n",
      "0.7676\n",
      "0.3853130241415258\n"
     ]
    }
   ],
   "source": [
    "recall_molly, recall_molly_ = multi_class_weighting(y, y_pred, recall)\n",
    "recall_sklearn = recall_score(y_true=y, y_pred=y_pred, average=\"weighted\")\n",
    "print(float_equal(recall_molly, recall_sklearn))\n",
    "print(recall_sklearn)\n",
    "print(recall_molly_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1(y_pred, y):\n",
    "    p = precision(y_pred, y)\n",
    "    r = recall(y_pred, y)\n",
    "    return 2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8339762002462043, 0.7347001223990207, 0.3033620015637216]\n",
      "[5778, 3292, 930]\n",
      "True\n",
      "0.7519473949414406\n",
      "0.4469473826238354\n"
     ]
    }
   ],
   "source": [
    "f1_molly, f1_molly_ = multi_class_weighting(y, y_pred, f1)\n",
    "f1_sklearn = f1_score(y_true=y, y_pred=y_pred, average=\"weighted\")\n",
    "print(float_equal(f1_molly, f1_sklearn))\n",
    "print(f1_sklearn)\n",
    "print(f1_molly_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
